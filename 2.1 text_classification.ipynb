{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tongs/Documents/Hugging Face/hugging-env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.999869704246521}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default model for sentiment-analysis\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\") # distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
    "classifier(\"This was a great movie!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.999869704246521}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default model via task for sentiment-analysis\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task = \"sentiment-analysis\") # distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
    "classifier(\"This was a great movie!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.999869704246521}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default model for text-classification\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task = \"text-classification\")\n",
    "classifier(\"This was a great movie!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy: 89.68%\n"
     ]
    }
   ],
   "source": [
    "# sentiment analysis \n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "\n",
    "reviews = load_dataset(\"rotten_tomatoes\")\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\") # default - distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
    "\n",
    "def label(review):\n",
    "    label = classifier(review)[0]['label']\n",
    "    if label == 'POSITIVE':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "test_df = reviews['test'].to_pandas()\n",
    "test_df['predicted_label'] = test_df['text'].apply(label)\n",
    "accuracy = (test_df['predicted_label'] == test_df['label']).mean()\n",
    "print(f\"model accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    }
   ],
   "source": [
    "# text classification\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "\n",
    "reviews = load_dataset(\"rotten_tomatoes\")\n",
    "classifier = pipeline(\"text-classification\", model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\") # default - distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
    "\n",
    "def label(review):\n",
    "    label = classifier(review)[0]['label']\n",
    "    if label == 'POSITIVE':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "test_df = reviews['test'].to_pandas()\n",
    "test_df['predicted_label'] = test_df['text'].apply(label)\n",
    "accuracy = (test_df['predicted_label'] == test_df['label']).mean()\n",
    "print(f\"model accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news text classification\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "\n",
    "reviews = load_dataset(\"rotten_tomatoes\")\n",
    "classifier = pipeline(task = \"text-classification\", model = \"ProsusAI/finbert\")\n",
    "\n",
    "def label(review):\n",
    "    label = classifier(review)[0]['label']\n",
    "    if label == 'POSITIVE':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "test_df = reviews['test'].to_pandas()\n",
    "test_df['predicted_label'] = test_df['text'].apply(label)\n",
    "accuracy = (test_df['predicted_label'] == test_df['label']).mean()\n",
    "print(f\"model accuracy: {accuracy:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugging-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
